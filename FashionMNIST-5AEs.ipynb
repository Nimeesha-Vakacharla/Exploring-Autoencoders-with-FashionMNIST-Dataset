{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2559a061-f5a1-4b9a-abc2-b3fd5e953599",
   "metadata": {},
   "source": [
    "<center>\n",
    " <h1>ASSIGMENT-05</h1>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    " <h3>DATA 266 GENERATIVE MODLE</h3>\n",
    "</center>\n",
    "\n",
    "\n",
    "<h5>Name: Gnana Prasuna Nimeesha Vakacharla </h5> \n",
    "<h5>SJSU ID: 017548115  </h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e624c02-28d7-4253-8259-69cb9eb1d278",
   "metadata": {},
   "source": [
    "2. Train and Evaluate Autoencoders on FashionMNIST Dataset (PyTorch)\n",
    "\n",
    " Implementing:\n",
    "- Fully Connected Autoencoder (FC-AE)\n",
    "- Convolutional Autoencoder (CNN-AE)\n",
    "- Sparse Autoencoder (Sparse-AE)\n",
    "- Recurrent Autoencoder (RNN-AE)\n",
    "- Variational Autoencoder (VAE)l (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47353d15-61e4-47a0-9200-9bd76eba992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ea7ba8-4a8c-47ee-a98a-8dd9786baecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FashionMNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0788be69-106c-4277-8e11-c15be378c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Autoencoder\n",
    "class FCAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten input\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(x.size(0), 1, 28, 28)  # Reshape back to image\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e5214d-7489-41dd-9669-86a0dd0e76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Autoencoder\n",
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1259657b-9069-45b4-8d8a-6ea1f857e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Autoencoder\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten input\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(x.size(0), 1, 28, 28)  # Reshape back to image\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93b80efd-cbc3-4fd8-9b93-f35b6f755f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent Autoencoder\n",
    "class RNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNAutoencoder, self).__init__()\n",
    "        self.encoder = nn.LSTM(28, 128, batch_first=True)\n",
    "        self.decoder = nn.LSTM(128, 28, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 28, 28)  # Reshape input for RNN (batch, seq, features)\n",
    "        x, _ = self.encoder(x)\n",
    "        x, _ = self.decoder(x)\n",
    "        x = x.view(x.size(0), 1, 28, 28)  # Reshape back to image\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e90f80ab-e5ed-45c6-9b28-1dbf22c56ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variational Autoencoder (VAE)\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=32):  # Added latent_dim as a parameter\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 400)\n",
    "        self.fc2_mean = nn.Linear(400, latent_dim)\n",
    "        self.fc2_logvar = nn.Linear(400, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, 400)\n",
    "        self.fc4 = nn.Linear(400, 28 * 28)\n",
    "        self.latent_dim = latent_dim # Store the latent dimension\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2_mean(h), self.fc2_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten input\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x = self.decode(z)\n",
    "        x = x.view(x.size(0), 1, 28, 28)  # Reshape back to image\n",
    "        return x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06d2bbc6-21d9-41a2-a14d-706306fc253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fully Connected Autoencoder...\n",
      "[FC-AE] Epoch [1/50], Train Loss: 0.0298, Test Loss: 0.0188\n",
      "[FC-AE] Epoch [2/50], Train Loss: 0.0170, Test Loss: 0.0157\n",
      "[FC-AE] Epoch [3/50], Train Loss: 0.0147, Test Loss: 0.0140\n",
      "[FC-AE] Epoch [4/50], Train Loss: 0.0132, Test Loss: 0.0127\n",
      "[FC-AE] Epoch [5/50], Train Loss: 0.0122, Test Loss: 0.0122\n",
      "[FC-AE] Epoch [6/50], Train Loss: 0.0115, Test Loss: 0.0114\n",
      "[FC-AE] Epoch [7/50], Train Loss: 0.0111, Test Loss: 0.0110\n",
      "[FC-AE] Epoch [8/50], Train Loss: 0.0107, Test Loss: 0.0106\n",
      "[FC-AE] Epoch [9/50], Train Loss: 0.0103, Test Loss: 0.0103\n",
      "[FC-AE] Epoch [10/50], Train Loss: 0.0100, Test Loss: 0.0101\n",
      "[FC-AE] Epoch [11/50], Train Loss: 0.0098, Test Loss: 0.0099\n",
      "[FC-AE] Epoch [12/50], Train Loss: 0.0096, Test Loss: 0.0097\n",
      "[FC-AE] Epoch [13/50], Train Loss: 0.0094, Test Loss: 0.0095\n",
      "[FC-AE] Epoch [14/50], Train Loss: 0.0093, Test Loss: 0.0094\n",
      "[FC-AE] Epoch [15/50], Train Loss: 0.0091, Test Loss: 0.0093\n",
      "[FC-AE] Epoch [16/50], Train Loss: 0.0090, Test Loss: 0.0092\n",
      "[FC-AE] Epoch [17/50], Train Loss: 0.0089, Test Loss: 0.0090\n",
      "[FC-AE] Epoch [18/50], Train Loss: 0.0088, Test Loss: 0.0089\n",
      "[FC-AE] Epoch [19/50], Train Loss: 0.0087, Test Loss: 0.0088\n",
      "[FC-AE] Epoch [20/50], Train Loss: 0.0086, Test Loss: 0.0088\n",
      "[FC-AE] Epoch [21/50], Train Loss: 0.0086, Test Loss: 0.0088\n",
      "[FC-AE] Epoch [22/50], Train Loss: 0.0085, Test Loss: 0.0086\n",
      "[FC-AE] Epoch [23/50], Train Loss: 0.0084, Test Loss: 0.0086\n",
      "[FC-AE] Epoch [24/50], Train Loss: 0.0084, Test Loss: 0.0085\n",
      "[FC-AE] Epoch [25/50], Train Loss: 0.0083, Test Loss: 0.0085\n",
      "[FC-AE] Epoch [26/50], Train Loss: 0.0083, Test Loss: 0.0084\n",
      "[FC-AE] Epoch [27/50], Train Loss: 0.0082, Test Loss: 0.0084\n",
      "[FC-AE] Epoch [28/50], Train Loss: 0.0082, Test Loss: 0.0083\n",
      "[FC-AE] Epoch [29/50], Train Loss: 0.0081, Test Loss: 0.0083\n",
      "[FC-AE] Epoch [30/50], Train Loss: 0.0081, Test Loss: 0.0083\n",
      "[FC-AE] Epoch [31/50], Train Loss: 0.0081, Test Loss: 0.0082\n",
      "[FC-AE] Epoch [32/50], Train Loss: 0.0080, Test Loss: 0.0082\n",
      "[FC-AE] Epoch [33/50], Train Loss: 0.0080, Test Loss: 0.0081\n",
      "[FC-AE] Epoch [34/50], Train Loss: 0.0080, Test Loss: 0.0082\n",
      "[FC-AE] Epoch [35/50], Train Loss: 0.0079, Test Loss: 0.0081\n",
      "[FC-AE] Epoch [36/50], Train Loss: 0.0079, Test Loss: 0.0081\n",
      "[FC-AE] Epoch [37/50], Train Loss: 0.0079, Test Loss: 0.0083\n",
      "[FC-AE] Epoch [38/50], Train Loss: 0.0079, Test Loss: 0.0081\n",
      "[FC-AE] Epoch [39/50], Train Loss: 0.0078, Test Loss: 0.0080\n",
      "[FC-AE] Epoch [40/50], Train Loss: 0.0078, Test Loss: 0.0080\n",
      "[FC-AE] Epoch [41/50], Train Loss: 0.0078, Test Loss: 0.0081\n",
      "[FC-AE] Epoch [42/50], Train Loss: 0.0078, Test Loss: 0.0080\n",
      "[FC-AE] Epoch [43/50], Train Loss: 0.0078, Test Loss: 0.0079\n",
      "[FC-AE] Epoch [44/50], Train Loss: 0.0078, Test Loss: 0.0080\n",
      "[FC-AE] Epoch [45/50], Train Loss: 0.0077, Test Loss: 0.0080\n",
      "[FC-AE] Epoch [46/50], Train Loss: 0.0077, Test Loss: 0.0080\n",
      "[FC-AE] Epoch [47/50], Train Loss: 0.0077, Test Loss: 0.0079\n",
      "[FC-AE] Epoch [48/50], Train Loss: 0.0077, Test Loss: 0.0079\n",
      "[FC-AE] Epoch [49/50], Train Loss: 0.0077, Test Loss: 0.0079\n",
      "[FC-AE] Epoch [50/50], Train Loss: 0.0077, Test Loss: 0.0079\n",
      "Training Convolutional Autoencoder...\n",
      "[CNN-AE] Epoch [1/50], Train Loss: 0.0176, Test Loss: 0.0085\n",
      "[CNN-AE] Epoch [2/50], Train Loss: 0.0071, Test Loss: 0.0062\n",
      "[CNN-AE] Epoch [3/50], Train Loss: 0.0057, Test Loss: 0.0054\n",
      "[CNN-AE] Epoch [4/50], Train Loss: 0.0050, Test Loss: 0.0050\n",
      "[CNN-AE] Epoch [5/50], Train Loss: 0.0046, Test Loss: 0.0046\n",
      "[CNN-AE] Epoch [6/50], Train Loss: 0.0044, Test Loss: 0.0044\n",
      "[CNN-AE] Epoch [7/50], Train Loss: 0.0043, Test Loss: 0.0043\n",
      "[CNN-AE] Epoch [8/50], Train Loss: 0.0041, Test Loss: 0.0041\n",
      "[CNN-AE] Epoch [9/50], Train Loss: 0.0040, Test Loss: 0.0040\n",
      "[CNN-AE] Epoch [10/50], Train Loss: 0.0040, Test Loss: 0.0040\n",
      "[CNN-AE] Epoch [11/50], Train Loss: 0.0039, Test Loss: 0.0040\n",
      "[CNN-AE] Epoch [12/50], Train Loss: 0.0038, Test Loss: 0.0038\n",
      "[CNN-AE] Epoch [13/50], Train Loss: 0.0038, Test Loss: 0.0038\n",
      "[CNN-AE] Epoch [14/50], Train Loss: 0.0037, Test Loss: 0.0037\n",
      "[CNN-AE] Epoch [15/50], Train Loss: 0.0037, Test Loss: 0.0037\n",
      "[CNN-AE] Epoch [16/50], Train Loss: 0.0037, Test Loss: 0.0037\n",
      "[CNN-AE] Epoch [17/50], Train Loss: 0.0036, Test Loss: 0.0036\n",
      "[CNN-AE] Epoch [18/50], Train Loss: 0.0036, Test Loss: 0.0036\n",
      "[CNN-AE] Epoch [19/50], Train Loss: 0.0036, Test Loss: 0.0036\n",
      "[CNN-AE] Epoch [20/50], Train Loss: 0.0035, Test Loss: 0.0036\n",
      "[CNN-AE] Epoch [21/50], Train Loss: 0.0035, Test Loss: 0.0035\n",
      "[CNN-AE] Epoch [22/50], Train Loss: 0.0035, Test Loss: 0.0035\n",
      "[CNN-AE] Epoch [23/50], Train Loss: 0.0035, Test Loss: 0.0035\n",
      "[CNN-AE] Epoch [24/50], Train Loss: 0.0035, Test Loss: 0.0035\n",
      "[CNN-AE] Epoch [25/50], Train Loss: 0.0034, Test Loss: 0.0034\n",
      "[CNN-AE] Epoch [26/50], Train Loss: 0.0034, Test Loss: 0.0035\n",
      "[CNN-AE] Epoch [27/50], Train Loss: 0.0034, Test Loss: 0.0034\n",
      "[CNN-AE] Epoch [28/50], Train Loss: 0.0034, Test Loss: 0.0035\n",
      "[CNN-AE] Epoch [29/50], Train Loss: 0.0034, Test Loss: 0.0034\n",
      "[CNN-AE] Epoch [30/50], Train Loss: 0.0034, Test Loss: 0.0034\n",
      "[CNN-AE] Epoch [31/50], Train Loss: 0.0033, Test Loss: 0.0034\n",
      "[CNN-AE] Epoch [32/50], Train Loss: 0.0033, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [33/50], Train Loss: 0.0033, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [34/50], Train Loss: 0.0033, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [35/50], Train Loss: 0.0033, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [36/50], Train Loss: 0.0033, Test Loss: 0.0034\n",
      "[CNN-AE] Epoch [37/50], Train Loss: 0.0033, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [38/50], Train Loss: 0.0033, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [39/50], Train Loss: 0.0032, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [40/50], Train Loss: 0.0032, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [41/50], Train Loss: 0.0032, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [42/50], Train Loss: 0.0032, Test Loss: 0.0032\n",
      "[CNN-AE] Epoch [43/50], Train Loss: 0.0032, Test Loss: 0.0033\n",
      "[CNN-AE] Epoch [44/50], Train Loss: 0.0032, Test Loss: 0.0032\n",
      "[CNN-AE] Epoch [45/50], Train Loss: 0.0032, Test Loss: 0.0032\n",
      "[CNN-AE] Epoch [46/50], Train Loss: 0.0032, Test Loss: 0.0032\n",
      "[CNN-AE] Epoch [47/50], Train Loss: 0.0032, Test Loss: 0.0032\n",
      "[CNN-AE] Epoch [48/50], Train Loss: 0.0032, Test Loss: 0.0032\n",
      "[CNN-AE] Epoch [49/50], Train Loss: 0.0032, Test Loss: 0.0032\n",
      "[CNN-AE] Epoch [50/50], Train Loss: 0.0032, Test Loss: 0.0032\n",
      "Training Sparse Autoencoder...\n",
      "[Sparse-AE] Epoch [1/50], Train Loss: 0.0302, Test Loss: 0.0192\n",
      "[Sparse-AE] Epoch [2/50], Train Loss: 0.0173, Test Loss: 0.0159\n",
      "[Sparse-AE] Epoch [3/50], Train Loss: 0.0148, Test Loss: 0.0141\n",
      "[Sparse-AE] Epoch [4/50], Train Loss: 0.0135, Test Loss: 0.0130\n",
      "[Sparse-AE] Epoch [5/50], Train Loss: 0.0125, Test Loss: 0.0122\n",
      "[Sparse-AE] Epoch [6/50], Train Loss: 0.0118, Test Loss: 0.0116\n",
      "[Sparse-AE] Epoch [7/50], Train Loss: 0.0112, Test Loss: 0.0112\n",
      "[Sparse-AE] Epoch [8/50], Train Loss: 0.0108, Test Loss: 0.0111\n",
      "[Sparse-AE] Epoch [9/50], Train Loss: 0.0105, Test Loss: 0.0105\n",
      "[Sparse-AE] Epoch [10/50], Train Loss: 0.0102, Test Loss: 0.0102\n",
      "[Sparse-AE] Epoch [11/50], Train Loss: 0.0100, Test Loss: 0.0100\n",
      "[Sparse-AE] Epoch [12/50], Train Loss: 0.0097, Test Loss: 0.0098\n",
      "[Sparse-AE] Epoch [13/50], Train Loss: 0.0095, Test Loss: 0.0096\n",
      "[Sparse-AE] Epoch [14/50], Train Loss: 0.0094, Test Loss: 0.0095\n",
      "[Sparse-AE] Epoch [15/50], Train Loss: 0.0092, Test Loss: 0.0092\n",
      "[Sparse-AE] Epoch [16/50], Train Loss: 0.0091, Test Loss: 0.0093\n",
      "[Sparse-AE] Epoch [17/50], Train Loss: 0.0090, Test Loss: 0.0090\n",
      "[Sparse-AE] Epoch [18/50], Train Loss: 0.0088, Test Loss: 0.0090\n",
      "[Sparse-AE] Epoch [19/50], Train Loss: 0.0087, Test Loss: 0.0089\n",
      "[Sparse-AE] Epoch [20/50], Train Loss: 0.0086, Test Loss: 0.0088\n",
      "[Sparse-AE] Epoch [21/50], Train Loss: 0.0085, Test Loss: 0.0087\n",
      "[Sparse-AE] Epoch [22/50], Train Loss: 0.0085, Test Loss: 0.0086\n",
      "[Sparse-AE] Epoch [23/50], Train Loss: 0.0084, Test Loss: 0.0086\n",
      "[Sparse-AE] Epoch [24/50], Train Loss: 0.0083, Test Loss: 0.0085\n",
      "[Sparse-AE] Epoch [25/50], Train Loss: 0.0082, Test Loss: 0.0084\n",
      "[Sparse-AE] Epoch [26/50], Train Loss: 0.0082, Test Loss: 0.0084\n",
      "[Sparse-AE] Epoch [27/50], Train Loss: 0.0081, Test Loss: 0.0084\n",
      "[Sparse-AE] Epoch [28/50], Train Loss: 0.0081, Test Loss: 0.0082\n",
      "[Sparse-AE] Epoch [29/50], Train Loss: 0.0080, Test Loss: 0.0082\n",
      "[Sparse-AE] Epoch [30/50], Train Loss: 0.0080, Test Loss: 0.0082\n",
      "[Sparse-AE] Epoch [31/50], Train Loss: 0.0079, Test Loss: 0.0082\n",
      "[Sparse-AE] Epoch [32/50], Train Loss: 0.0079, Test Loss: 0.0081\n",
      "[Sparse-AE] Epoch [33/50], Train Loss: 0.0079, Test Loss: 0.0081\n",
      "[Sparse-AE] Epoch [34/50], Train Loss: 0.0078, Test Loss: 0.0080\n",
      "[Sparse-AE] Epoch [35/50], Train Loss: 0.0078, Test Loss: 0.0080\n",
      "[Sparse-AE] Epoch [36/50], Train Loss: 0.0078, Test Loss: 0.0081\n",
      "[Sparse-AE] Epoch [37/50], Train Loss: 0.0078, Test Loss: 0.0079\n",
      "[Sparse-AE] Epoch [38/50], Train Loss: 0.0077, Test Loss: 0.0079\n",
      "[Sparse-AE] Epoch [39/50], Train Loss: 0.0077, Test Loss: 0.0079\n",
      "[Sparse-AE] Epoch [40/50], Train Loss: 0.0077, Test Loss: 0.0079\n",
      "[Sparse-AE] Epoch [41/50], Train Loss: 0.0077, Test Loss: 0.0079\n",
      "[Sparse-AE] Epoch [42/50], Train Loss: 0.0077, Test Loss: 0.0079\n",
      "[Sparse-AE] Epoch [43/50], Train Loss: 0.0076, Test Loss: 0.0078\n",
      "[Sparse-AE] Epoch [44/50], Train Loss: 0.0076, Test Loss: 0.0079\n",
      "[Sparse-AE] Epoch [45/50], Train Loss: 0.0076, Test Loss: 0.0078\n",
      "[Sparse-AE] Epoch [46/50], Train Loss: 0.0076, Test Loss: 0.0078\n",
      "[Sparse-AE] Epoch [47/50], Train Loss: 0.0076, Test Loss: 0.0078\n",
      "[Sparse-AE] Epoch [48/50], Train Loss: 0.0076, Test Loss: 0.0078\n",
      "[Sparse-AE] Epoch [49/50], Train Loss: 0.0076, Test Loss: 0.0078\n",
      "[Sparse-AE] Epoch [50/50], Train Loss: 0.0075, Test Loss: 0.0078\n",
      "Training Recurrent Autoencoder...\n",
      "[RNN-AE] Epoch [1/50], Train Loss: 0.0121, Test Loss: 0.0021\n",
      "[RNN-AE] Epoch [2/50], Train Loss: 0.0014, Test Loss: 0.0011\n",
      "[RNN-AE] Epoch [3/50], Train Loss: 0.0010, Test Loss: 0.0008\n",
      "[RNN-AE] Epoch [4/50], Train Loss: 0.0008, Test Loss: 0.0007\n",
      "[RNN-AE] Epoch [5/50], Train Loss: 0.0006, Test Loss: 0.0006\n",
      "[RNN-AE] Epoch [6/50], Train Loss: 0.0006, Test Loss: 0.0006\n",
      "[RNN-AE] Epoch [7/50], Train Loss: 0.0005, Test Loss: 0.0005\n",
      "[RNN-AE] Epoch [8/50], Train Loss: 0.0005, Test Loss: 0.0005\n",
      "[RNN-AE] Epoch [9/50], Train Loss: 0.0005, Test Loss: 0.0004\n",
      "[RNN-AE] Epoch [10/50], Train Loss: 0.0004, Test Loss: 0.0004\n",
      "[RNN-AE] Epoch [11/50], Train Loss: 0.0004, Test Loss: 0.0004\n",
      "[RNN-AE] Epoch [12/50], Train Loss: 0.0004, Test Loss: 0.0004\n",
      "[RNN-AE] Epoch [13/50], Train Loss: 0.0004, Test Loss: 0.0004\n",
      "[RNN-AE] Epoch [14/50], Train Loss: 0.0004, Test Loss: 0.0003\n",
      "[RNN-AE] Epoch [15/50], Train Loss: 0.0003, Test Loss: 0.0003\n",
      "[RNN-AE] Epoch [16/50], Train Loss: 0.0003, Test Loss: 0.0003\n",
      "[RNN-AE] Epoch [17/50], Train Loss: 0.0003, Test Loss: 0.0003\n",
      "[RNN-AE] Epoch [18/50], Train Loss: 0.0003, Test Loss: 0.0003\n",
      "[RNN-AE] Epoch [19/50], Train Loss: 0.0003, Test Loss: 0.0002\n",
      "[RNN-AE] Epoch [20/50], Train Loss: 0.0002, Test Loss: 0.0002\n",
      "[RNN-AE] Epoch [21/50], Train Loss: 0.0002, Test Loss: 0.0002\n",
      "[RNN-AE] Epoch [22/50], Train Loss: 0.0002, Test Loss: 0.0002\n",
      "[RNN-AE] Epoch [23/50], Train Loss: 0.0002, Test Loss: 0.0002\n",
      "[RNN-AE] Epoch [24/50], Train Loss: 0.0002, Test Loss: 0.0002\n",
      "[RNN-AE] Epoch [25/50], Train Loss: 0.0002, Test Loss: 0.0002\n",
      "[RNN-AE] Epoch [26/50], Train Loss: 0.0002, Test Loss: 0.0002\n",
      "[RNN-AE] Epoch [27/50], Train Loss: 0.0002, Test Loss: 0.0002\n",
      "[RNN-AE] Epoch [28/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [29/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [30/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [31/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [32/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [33/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [34/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [35/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [36/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [37/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [38/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [39/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [40/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [41/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [42/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [43/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [44/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [45/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [46/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [47/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [48/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [49/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "[RNN-AE] Epoch [50/50], Train Loss: 0.0001, Test Loss: 0.0001\n",
      "Training Variational Autoencoder...\n",
      "[VAE] Epoch [1/50], Train Loss: 0.0822, Test Loss: 0.0774\n",
      "[VAE] Epoch [2/50], Train Loss: 0.0758, Test Loss: 0.0742\n",
      "[VAE] Epoch [3/50], Train Loss: 0.0745, Test Loss: 0.0741\n",
      "[VAE] Epoch [4/50], Train Loss: 0.0742, Test Loss: 0.0740\n",
      "[VAE] Epoch [5/50], Train Loss: 0.0740, Test Loss: 0.0736\n",
      "[VAE] Epoch [6/50], Train Loss: 0.0737, Test Loss: 0.0734\n",
      "[VAE] Epoch [7/50], Train Loss: 0.0737, Test Loss: 0.0735\n",
      "[VAE] Epoch [8/50], Train Loss: 0.0734, Test Loss: 0.0731\n",
      "[VAE] Epoch [9/50], Train Loss: 0.0735, Test Loss: 0.0736\n",
      "[VAE] Epoch [10/50], Train Loss: 0.0734, Test Loss: 0.0735\n",
      "[VAE] Epoch [11/50], Train Loss: 0.0733, Test Loss: 0.0727\n",
      "[VAE] Epoch [12/50], Train Loss: 0.0734, Test Loss: 0.0730\n",
      "[VAE] Epoch [13/50], Train Loss: 0.0733, Test Loss: 0.0730\n",
      "[VAE] Epoch [14/50], Train Loss: 0.0732, Test Loss: 0.0732\n",
      "[VAE] Epoch [15/50], Train Loss: 0.0732, Test Loss: 0.0730\n",
      "[VAE] Epoch [16/50], Train Loss: 0.0733, Test Loss: 0.0729\n",
      "[VAE] Epoch [17/50], Train Loss: 0.0732, Test Loss: 0.0726\n",
      "[VAE] Epoch [18/50], Train Loss: 0.0731, Test Loss: 0.0728\n",
      "[VAE] Epoch [19/50], Train Loss: 0.0732, Test Loss: 0.0728\n",
      "[VAE] Epoch [20/50], Train Loss: 0.0729, Test Loss: 0.0725\n",
      "[VAE] Epoch [21/50], Train Loss: 0.0731, Test Loss: 0.0728\n",
      "[VAE] Epoch [22/50], Train Loss: 0.0730, Test Loss: 0.0727\n",
      "[VAE] Epoch [23/50], Train Loss: 0.0730, Test Loss: 0.0727\n",
      "[VAE] Epoch [24/50], Train Loss: 0.0730, Test Loss: 0.0727\n",
      "[VAE] Epoch [25/50], Train Loss: 0.0729, Test Loss: 0.0726\n",
      "[VAE] Epoch [26/50], Train Loss: 0.0731, Test Loss: 0.0727\n",
      "[VAE] Epoch [27/50], Train Loss: 0.0729, Test Loss: 0.0730\n",
      "[VAE] Epoch [28/50], Train Loss: 0.0730, Test Loss: 0.0727\n",
      "[VAE] Epoch [29/50], Train Loss: 0.0731, Test Loss: 0.0725\n",
      "[VAE] Epoch [30/50], Train Loss: 0.0731, Test Loss: 0.0727\n",
      "[VAE] Epoch [31/50], Train Loss: 0.0731, Test Loss: 0.0727\n",
      "[VAE] Epoch [32/50], Train Loss: 0.0730, Test Loss: 0.0727\n",
      "[VAE] Epoch [33/50], Train Loss: 0.0730, Test Loss: 0.0727\n",
      "[VAE] Epoch [34/50], Train Loss: 0.0729, Test Loss: 0.0732\n",
      "[VAE] Epoch [35/50], Train Loss: 0.0730, Test Loss: 0.0728\n",
      "[VAE] Epoch [36/50], Train Loss: 0.0729, Test Loss: 0.0726\n",
      "[VAE] Epoch [37/50], Train Loss: 0.0728, Test Loss: 0.0730\n",
      "[VAE] Epoch [38/50], Train Loss: 0.0729, Test Loss: 0.0729\n",
      "[VAE] Epoch [39/50], Train Loss: 0.0730, Test Loss: 0.0728\n",
      "[VAE] Epoch [40/50], Train Loss: 0.0729, Test Loss: 0.0728\n",
      "[VAE] Epoch [41/50], Train Loss: 0.0728, Test Loss: 0.0725\n",
      "[VAE] Epoch [42/50], Train Loss: 0.0729, Test Loss: 0.0729\n",
      "[VAE] Epoch [43/50], Train Loss: 0.0729, Test Loss: 0.0727\n",
      "[VAE] Epoch [44/50], Train Loss: 0.0730, Test Loss: 0.0730\n",
      "[VAE] Epoch [45/50], Train Loss: 0.0730, Test Loss: 0.0727\n",
      "[VAE] Epoch [46/50], Train Loss: 0.0729, Test Loss: 0.0728\n",
      "[VAE] Epoch [47/50], Train Loss: 0.0728, Test Loss: 0.0727\n",
      "[VAE] Epoch [48/50], Train Loss: 0.0730, Test Loss: 0.0725\n",
      "[VAE] Epoch [49/50], Train Loss: 0.0729, Test Loss: 0.0727\n",
      "[VAE] Epoch [50/50], Train Loss: 0.0728, Test Loss: 0.0725\n",
      "\n",
      "Final Losses:\n",
      "FC-AE - Train Loss: 0.0077, Test Loss: 0.0079\n",
      "CNN-AE - Train Loss: 0.0032, Test Loss: 0.0032\n",
      "Sparse-AE - Train Loss: 0.0075, Test Loss: 0.0078\n",
      "RNN-AE - Train Loss: 0.0001, Test Loss: 0.0001\n",
      "VAE - Train Loss: 0.0728, Test Loss: 0.0725\n"
     ]
    }
   ],
   "source": [
    "# Training Function\n",
    "\n",
    "\n",
    "# Initialize Autoencoders\n",
    "fc_autoencoder = FCAutoencoder()\n",
    "cnn_autoencoder = CNNAutoencoder()\n",
    "sparse_autoencoder = SparseAutoencoder()\n",
    "rnn_autoencoder = RNNAutoencoder()\n",
    "vae_autoencoder = VAE()\n",
    "\n",
    "# Global variables to store final losses\n",
    "final_train_losses = {}\n",
    "final_test_losses = {}\n",
    "\n",
    "# Training Function\n",
    "def train_autoencoder(model, train_loader, test_loader, model_name, epochs=50, beta=0.5):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data, _ in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if isinstance(model, VAE):\n",
    "                output, mu, logvar = model(data)\n",
    "                #Adjusted loss calculation with beta\n",
    "                loss = criterion(output, data) + beta * 0.5 * torch.mean(-1 - logvar + mu.pow(2) + logvar.exp())\n",
    "            else:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, data)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, _ in test_loader:\n",
    "                data = data.to(device)\n",
    "                if isinstance(model, VAE):\n",
    "                    output, mu, logvar = model(data)\n",
    "                    #Adjusted loss calculation with beta\n",
    "                    loss = criterion(output, data) + beta * 0.5 * torch.mean(-1 - logvar + mu.pow(2) + logvar.exp())\n",
    "                else:\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, data)\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        \n",
    "        # Print training status for the current model\n",
    "        print(f\"[{model_name}] Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Store final losses\n",
    "    final_train_losses[model_name] = train_loss\n",
    "    final_test_losses[model_name] = test_loss\n",
    "\n",
    "# Train Models and Print Status\n",
    "print(\"Training Fully Connected Autoencoder...\")\n",
    "train_autoencoder(fc_autoencoder, train_loader, test_loader, 'FC-AE')\n",
    "\n",
    "print(\"Training Convolutional Autoencoder...\")\n",
    "train_autoencoder(cnn_autoencoder, train_loader, test_loader, 'CNN-AE')\n",
    "\n",
    "print(\"Training Sparse Autoencoder...\")\n",
    "train_autoencoder(sparse_autoencoder, train_loader, test_loader, 'Sparse-AE')\n",
    "\n",
    "print(\"Training Recurrent Autoencoder...\")\n",
    "train_autoencoder(rnn_autoencoder, train_loader, test_loader, 'RNN-AE')\n",
    "\n",
    "print(\"Training Variational Autoencoder...\")\n",
    "train_autoencoder(vae_autoencoder, train_loader, test_loader, 'VAE')\n",
    "\n",
    "# Print Final Losses\n",
    "print(\"\\nFinal Losses:\")\n",
    "for name in final_train_losses:\n",
    "    print(f\"{name} - Train Loss: {final_train_losses[name]:.4f}, Test Loss: {final_test_losses[name]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a22932e4-3aef-452b-81ed-95ca3ff269c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate and Visualize Results\n",
    "def evaluate_and_visualize(models, test_loader):\n",
    "    test_data = next(iter(test_loader))[0][:1].to(device)\n",
    "    fig, axs = plt.subplots(1, 6, figsize=(15, 3))\n",
    "    axs[0].imshow(test_data.cpu().squeeze(), cmap='gray')\n",
    "    axs[0].set_title('Original')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    for i, (name, model) in enumerate(models.items(), start=1):\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if name == 'VAE':\n",
    "                decoded, _, _ = model(test_data)  # Get output, mu, logvar\n",
    "            else:\n",
    "                decoded = model(test_data) # Get output\n",
    "        axs[i].imshow(decoded.cpu().squeeze(), cmap='gray')\n",
    "        axs[i].set_title(name)\n",
    "        axs[i].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Dictionary of models\n",
    "models = {\n",
    "    'FC-AE': fc_autoencoder,\n",
    "    'CNN-AE': cnn_autoencoder,\n",
    "    'Sparse-AE': sparse_autoencoder,\n",
    "    'RNN-AE': rnn_autoencoder,\n",
    "    'VAE': vae_autoencoder\n",
    "}\n",
    "\n",
    "evaluate_and_visualize(models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb154665-50f2-4233-bc94-69efdf9d8ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d285256-c768-424a-8e7a-3180021613b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
